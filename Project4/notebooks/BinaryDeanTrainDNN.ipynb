{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WannXu5Dq3vp",
        "2SMmKtAfrxG1",
        "5roqMCBht-2m",
        "pZWkBPi2Q3S4",
        "OhXbv2TMtk9Z",
        "W5FC29BUAvlR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.9.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "rUnbeyH_YTUk",
        "outputId": "69725a56-c0c4-41f5-f3ee-503ccc0e208c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.4 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.9.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 keras-2.9.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "30c716c667604704ba01dc288423d6fc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlalchemy\n",
        "from sqlalchemy import text\n",
        "from sqlalchemy.ext.automap import automap_base\n",
        "from sqlalchemy.orm import Session\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "import pickle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "engine = create_engine('postgresql+psycopg2://breast_cancer_dataset_user:UnSNEeECgY7ky2i5KAPC2WtQn9XrRpvc@dpg-cnbvjf779t8c73epbb3g-a.oregon-postgres.render.com/breast_cancer_dataset')\n",
        "with engine.connect() as connection:\n",
        "    # Adjust the SQL query based on your database schema and structure\n",
        "    query = text(\"\"\"\n",
        "    SELECT\n",
        "    der_age_trunc, der_obesity, der_race_v2, der_smoking2,\n",
        "    urban_rural, severity_of_covid_19_v2, der_cancertr_none, der_cancer_status_v4, der_dm2,\n",
        "    der_card, der_pulm, der_renal\n",
        "    FROM Raw_DataFrame\n",
        "    \"\"\" )\n",
        "    result = connection.execute(query)\n",
        "\n",
        "    data = pd.DataFrame(result.fetchall(),\n",
        "                                        columns=[\"der_age_trunc\", \"der_obesity\",\"der_race_v2\",\n",
        "                                            \"der_smoking2\", \"urban_rural\", \"severity_of_covid_19_v2\",\n",
        "                                            \"der_cancertr_none\", \"der_cancer_status_v4\", \"der_dm2\",\n",
        "                                            \"der_card\", \"der_pulm\", \"der_renal\"])\n",
        "\n",
        "data.dropna(inplace= True)\n",
        "f\"Number of rows in data: {len(data)}\""
      ],
      "metadata": {
        "id": "Gf_krtI26tD0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "befd1850-8389-4c85-f982-774b1fabbcb3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Number of rows in data: 1044'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['der_age_trunc'].max(), data['der_age_trunc'].min()"
      ],
      "metadata": {
        "id": "7lr-3JhTqLoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for c in data.columns:\n",
        "#  print(data[c].value_counts())\n",
        "#  print()"
      ],
      "metadata": {
        "id": "oWhLIwo_E-YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training configuration\n",
        "config = {\n",
        "    'learning_rate': 1e-2,\n",
        "    'hidden': 128,\n",
        "    'epochs': 50,\n",
        "    'batch_size': 16,\n",
        "    'monitor': 'val_auc', # 'val_accuracy', 'val_auc_score', 'val_loss'\n",
        "    'verbose': 0,\n",
        "}"
      ],
      "metadata": {
        "id": "iVoj4v7P6Fr5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Objects"
      ],
      "metadata": {
        "id": "WannXu5Dq3vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_categorical = ['der_race_v2', 'der_smoking2', 'urban_rural', 'der_cancer_status_v4']\n",
        "binary = ['der_obesity', 'der_cancertr_none', 'der_dm2', 'der_card', 'der_pulm', 'der_renal']\n",
        "continuous = ['der_age_trunc']\n",
        "target = 'severity_of_covid_19_v2'"
      ],
      "metadata": {
        "id": "rA_fOEUZ6mJX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "enc.fit(data[multi_categorical + binary].values)\n",
        "\n",
        "with open('ohe.pkl', 'wb') as f:\n",
        "  pickle.dump(enc, f)"
      ],
      "metadata": {
        "id": "6BatZrjefU-r"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(data[continuous].values)\n",
        "\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "  pickle.dump(scaler, f)"
      ],
      "metadata": {
        "id": "6vFDrDWxgtAv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Training dataset"
      ],
      "metadata": {
        "id": "2SMmKtAfrxG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_continous = scaler.transform(data[continuous].values)\n",
        "X_categorical = enc.transform(data[multi_categorical + binary].values)\n",
        "X = np.concatenate([X_continous, X_categorical], axis=-1)\n",
        "\n",
        "y = data['severity_of_covid_19_v2'].map({'Mild': 0, 'Moderate': 1, 'Severe': 1}).values\n",
        "y = np.expand_dims(y, axis=-1).astype('float32')\n",
        "\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBbtzIG4qeZG",
        "outputId": "e40b689b-6b0a-4820-9fe9-24cfe8280ad1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1044, 29), (1044, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['severity_of_covid_19_v2'].map({'Mild': 0, 'Moderate': 1, 'Severe': 1}).values\n",
        "y = np.expand_dims(y, axis=-1).astype('float32')\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crJYoB_j5XX7",
        "outputId": "003a588f-2130-4a95-9fee-f71fff2d88cf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1044, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, counts = np.unique(y, return_counts=1)\n",
        "counts / counts.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb_braTo7pxO",
        "outputId": "ad9c2a1a-8d66-4c44-f24e-4ad8f11a88d2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.72796935, 0.27203065])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Setup"
      ],
      "metadata": {
        "id": "5roqMCBht-2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, hidden):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(hidden, activation='relu'),\n",
        "        tf.keras.layers.Dense(hidden, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "def create_model(hidden, learning_rate=1e-4):\n",
        "  nn = point_wise_feed_forward_network(1, hidden)\n",
        "  nn.compile(loss=\"binary_crossentropy\",\n",
        "             optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "             metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
        "  return nn\n"
      ],
      "metadata": {
        "id": "nS0Y3lBbuA0p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model_filepath,\n",
        "          x_train, y_train,\n",
        "          x_test, y_test,\n",
        "          config):\n",
        "  model = create_model(config['hidden'], config['learning_rate'])\n",
        "\n",
        "  verbose = config['verbose']\n",
        "  monitor = config['monitor']\n",
        "  callbacks = [\n",
        "      tf.keras.callbacks.ReduceLROnPlateau(\n",
        "          monitor=monitor, factor=0.1, patience=10,\n",
        "          verbose=verbose, min_lr=1e-6),\n",
        "      tf.keras.callbacks.ModelCheckpoint(\n",
        "          model_filepath, save_best_only=True,\n",
        "          monitor=monitor, verbose=verbose)\n",
        "      ]\n",
        "  hist = model.fit(x_train, y_train, validation_data=(x_test, y_test),\n",
        "                   epochs=config['epochs'], callbacks=callbacks,\n",
        "                   verbose=verbose).history\n",
        "\n",
        "  # results of model saved\n",
        "  model = tf.keras.models.load_model(model_filepath)\n",
        "  model.predict(x_test, verbose=verbose) # build\n",
        "  loss, acc, auc = model.evaluate(x_test, y_test, verbose=verbose)\n",
        "  best_scores = {'val_loss': loss, 'val_accuracy': acc, 'val_auc': auc}\n",
        "\n",
        "  return best_scores\n"
      ],
      "metadata": {
        "id": "RDwcaBfhxIBv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Single"
      ],
      "metadata": {
        "id": "q0AG9puD5wyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,\n",
        "                                                    stratify=y,\n",
        "                                                    random_state=12345)\n",
        "train('model.h5', X_train, y_train, X_test, y_test, config)"
      ],
      "metadata": {
        "id": "kpKfy0u25yKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf975fb-9b3e-4993-ee98-18fb9e3aaa0d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_loss': 0.8416507244110107,\n",
              " 'val_accuracy': 0.7142857313156128,\n",
              " 'val_auc': 0.7300363183021545}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross validation"
      ],
      "metadata": {
        "id": "OhXbv2TMtk9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=12345)\n",
        "\n",
        "\n",
        "scores = []\n",
        "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
        "\n",
        "    X_train, y_train = X[train_index], y[train_index]\n",
        "    X_test, y_test = X[test_index], y[test_index]\n",
        "\n",
        "    results = train('temp.keras', X_train, y_train, X_test, y_test, config)\n",
        "    print(f\"Fold {i}: {results}\")\n",
        "    scores.append(results[config['monitor']])\n",
        "\n",
        "f\"KFold results: {np.mean(scores)*100:.4f}\""
      ],
      "metadata": {
        "id": "abYGfsnmtY_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "id": "d7ylwrIOQscC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}